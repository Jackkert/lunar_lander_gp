{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolving a Lunar Lander with differentiable Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "To install the required libraries run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Imports from the standard genepro-multi library are done here. Any adjustments (e.g. different operators) should be made in the notebook. For example:\n",
    "\n",
    "```\n",
    "class SmoothOperator(Node):\n",
    "  def __init__(self):\n",
    "    super(SmoothOperator,self).__init__()\n",
    "    self.arity = 1\n",
    "    self.symb = \"SmoothOperator\"\n",
    "\n",
    "  def _get_args_repr(self, args):\n",
    "    return self._get_typical_repr(args,'before')\n",
    "\n",
    "  def get_output(self, X):\n",
    "    c_outs = self._get_child_outputs(X)\n",
    "    return np.smoothOperation(c_outs[0])\n",
    "\n",
    "  def get_output_pt(self, X):\n",
    "    c_outs = self._get_child_outputs_pt(X)\n",
    "    return torch.smoothOperation(c_outs[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "from genepro.node_impl import *\n",
    "from genepro.evo import Evolution\n",
    "from genepro.node_impl import Constant\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from matplotlib import animation\n",
    "\n",
    "from genepro.variation import subtree_crossover\n",
    "from genepro.variation  import subtree_mutation\n",
    "from genepro.variation import coeff_mutation\n",
    "from genepro.selection import tournament_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning Setup\n",
    "Here we first setup the Gymnasium environment. Please see https://gymnasium.farama.org/environments/box2d/lunar_lander/ for more information on the environment. \n",
    "\n",
    "Then a memory buffer is made. This is a buffer in which state transitions are stored. When the buffer reaches its maximum capacity old transitions are replaced by new ones.\n",
    "\n",
    "A frame buffer is initialised used to later store animation frames of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def __iadd__(self, other):\n",
    "      self.memory += other.memory\n",
    "      return self \n",
    "\n",
    "    def __add__(self, other):\n",
    "      self.memory = self.memory + other.memory \n",
    "      return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "seeds = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness Function\n",
    "\n",
    "Here you get to be creative. The default setup evaluates 5 episodes of 300 frames. Think of what action to pick and what fitness function to use. The Multi-tree takes an input of $n \\times d$ where $n$ is a batch of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraEpisodeDuration = 0\n",
    "def decisionFunction4Choices(multitree, input_sample):\n",
    "    return torch.argmax(multitree.get_output_pt(input_sample))\n",
    "\n",
    "def fitness_function_pt(multitree, num_episodes=6, episode_duration=10, render=False, ignore_done=False, seed = -1):\n",
    "  memory = ReplayMemory(10000)\n",
    "  rewards = []\n",
    "  wins = 0\n",
    "  games = 0\n",
    "  episodes =  num_episodes+difficulty\n",
    "  for i in range(episodes):\n",
    "    # get initial state of the environment\n",
    "    if(seed == -1):\n",
    "      observation = env.reset(seed=seeds[i])\n",
    "    else :\n",
    "      observation = env.reset(seed=seed)\n",
    "    \n",
    "    observation = observation[0]\n",
    "    currentReward = 0\n",
    "    for _ in range(episode_duration+extraEpisodeDuration):\n",
    "      if render:\n",
    "        frames.append(env.render())\n",
    "\n",
    "      input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "      \n",
    "      action = decisionFunction4Choices(multitree, input_sample)\n",
    "      observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "      currentReward = currentReward+reward\n",
    "      output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "      memory.push(input_sample, torch.tensor([[action.item()]]), output_sample, torch.tensor([reward]))\n",
    "      if (terminated or truncated) and not ignore_done:\n",
    "        break\n",
    "    if (currentReward > 200):\n",
    "      wins+=1\n",
    "      currentReward = 200\n",
    "    games = games + 1\n",
    "    currentReward = -1.02**(-currentReward)\n",
    "    rewards.append(currentReward)\n",
    "    \n",
    "  #fitness = int((multitree.wins*100/multitree.games))*1000 + np.sum(rewards) / (num_episodes+difficulty)\n",
    "  \n",
    "  percentage = (multitree.wins+wins)/(multitree.games+games)\n",
    "  extraPoints = (int((percentage)*100))*1000\n",
    "  \n",
    "  fitness = np.sum(rewards) / (episodes)\n",
    "  if(percentage>=2):\n",
    "    fitness = fitness+extraPoints\n",
    "  \n",
    "  return fitness, memory, wins, games\n",
    "\n",
    "\n",
    "def initSeeds(start = False):\n",
    "  global seeds\n",
    "  global seedsNumber\n",
    "  global difficulty\n",
    "  global extraEpisodeDuration\n",
    "  if(extraEpisodeDuration < 300):\n",
    "    extraEpisodeDuration += 10\n",
    "  if(start):\n",
    "    if(difficulty<0):\n",
    "      difficulty = difficulty + 1\n",
    "      print(f\"Increasing difficulty to {difficulty}\")\n",
    "  \n",
    "  seeds = [np.random.randint(32000) for _ in range(20)]\n",
    "  print(f\"seeds: {seeds}\")\n",
    "  return difficulty+6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Setup\n",
    "Here the leaf and internal nodes are defined. Think about the odds of sampling a constant in this default configurations. Also think about any operators that could be useful and add them here. \n",
    "\n",
    "Adjust the population size (multiple of 8 if you want to use the standard tournament selection), max generations and max tree size to taste. Be aware that each of these settings can increase the runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = env.observation_space.shape[0]\n",
    "leaf_nodes = [Feature(i) for i in range(num_features)]\n",
    "leaf_nodes = leaf_nodes + [Constant()] # Think about the probability of sampling a coefficient\n",
    "internal_nodes = [Plus(),Minus(),Times(),Div(),Sqrt(), Sin(), Cos(), Max(), Min()] #Add your own operators here\n",
    "\n",
    "evo = Evolution(\n",
    "  fitness_function_pt, internal_nodes, leaf_nodes,\n",
    "  4,\n",
    "  pop_size=80,\n",
    "  max_gens=500,\n",
    "  max_tree_size=100,\n",
    "  crossovers=[{\"fun\": subtree_crossover, \"rate\": 0.5}],\n",
    "  mutations=[{\"fun\": subtree_mutation, \"rate\": 0.5}],\n",
    "  coeff_opts =[{\"fun\":coeff_mutation, \"rate\": 0.4}],\n",
    "  selection ={\"fun\":tournament_selection,\"kwargs\":{\"tournament_size\":8}},\n",
    "  n_jobs=8,\n",
    "  verbose=True,\n",
    "  elitism=0.04\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolve\n",
    "Running this cell will use all the settings above as parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeds: [27358, 7452, 21075, 16432, 14992, 4045, 14773, 7859, 10353, 15923, 15916, 4101, 29645, 22991, 23481, 30532, 7789, 5678, 21934, 10886]\n",
      "seeds: [1044, 11505, 18255, 26532, 7184, 20449, 6956, 5395, 24683, 490, 1971, 8729, 10619, 16409, 15290, 16790, 22308, 30751, 2331, 5685]\n",
      "gen: 1,\tbest of gen fitness: 15.781,\tbest of gen size: 25\n",
      "Average fitness: 10.70, Standard deviation: 3.82, Minimum fitness: 1.92, Maximum fitness: 15.78, Best scores: 0/6, Best scores: 0.00/0.00, Median fitness: 12.56, Variance: 14.59\n",
      "seeds: [6489, 19362, 16244, 10637, 30016, 6122, 31088, 14888, 17518, 15183, 8602, 25732, 22278, 19043, 14264, 29564, 23269, 29858, 31324, 30981]\n",
      "gen: 2,\tbest of gen fitness: 97.641,\tbest of gen size: 32\n",
      "Average fitness: 69.45, Standard deviation: 21.51, Minimum fitness: 7.11, Maximum fitness: 97.64, Best scores: 0/6, Best scores: 0.00/2.36, Median fitness: 76.96, Variance: 462.71\n",
      "seeds: [8664, 19362, 9481, 13535, 21498, 15395, 14740, 7851, 22590, 22332, 5433, 15632, 3957, 27860, 4499, 14164, 2196, 21264, 21987, 13628]\n",
      "gen: 3,\tbest of gen fitness: 1278.297,\tbest of gen size: 45\n",
      "Average fitness: 536.54, Standard deviation: 184.59, Minimum fitness: 133.57, Maximum fitness: 1278.30, Best scores: 0/6, Best scores: 0.00/3.77, Median fitness: 553.61, Variance: 34073.19\n",
      "seeds: [7849, 2912, 4870, 21987, 843, 11471, 17912, 9036, 24435, 18108, 6933, 31507, 25310, 253, 7804, 30827, 21412, 25701, 13750, 6982]\n",
      "seeds: [16292, 30634, 4101, 2314, 25683, 3098, 9605, 18407, 16404, 7701, 19022, 15258, 4884, 13516, 16013, 20025, 7199, 13564, 20059, 3017]\n",
      "gen: 4,\tbest of gen fitness: 125269.694,\tbest of gen size: 36\n",
      "Average fitness: 71784.53, Standard deviation: 36126.62, Minimum fitness: 5.30, Maximum fitness: 125269.69, Best scores: 0/6, Best scores: 0.00/2.66, Median fitness: 90431.42, Variance: 1305132877.09\n",
      "seeds: [10356, 16685, 5429, 15768, 20477, 766, 28456, 13602, 24398, 12375, 13690, 23366, 21519, 29535, 13354, 14674, 19700, 29681, 31923, 19517]\n",
      "seeds: [23977, 22882, 7525, 22880, 1332, 20543, 22713, 29101, 2897, 2178, 22015, 30544, 23666, 6436, 20177, 19360, 23411, 2883, 7816, 22225]\n",
      "gen: 5,\tbest of gen fitness: 439742.275,\tbest of gen size: 23\n",
      "Average fitness: 108469.10, Standard deviation: 119827.84, Minimum fitness: 1787.23, Maximum fitness: 439742.27, Best scores: 0/6, Best scores: 0.00/3.08, Median fitness: 48692.35, Variance: 14358710118.59\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m evo\u001b[38;5;241m.\u001b[39minitSeeds \u001b[38;5;241m=\u001b[39m initSeeds\n\u001b[0;32m      3\u001b[0m difficulty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mevo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Facultati\\Delft\\M1\\Evolutionary Algorithms\\Lander\\genepro\\evo.py:321\u001b[0m, in \u001b[0;36mEvolution.evolve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# generational loop\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_must_terminate():\n\u001b[0;32m    320\u001b[0m   \u001b[38;5;66;03m# perform one generation\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m   \u001b[38;5;66;03m# log info\u001b[39;00m\n\u001b[0;32m    323\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[1;32md:\\Facultati\\Delft\\M1\\Evolutionary Algorithms\\Lander\\genepro\\evo.py:216\u001b[0m, in \u001b[0;36mEvolution._perform_generation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    213\u001b[0m elites \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mfitness, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[:elite_count])\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# generate offspring\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m offspring_population \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerate_offspring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[43m  \u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrossovers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoeff_opts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m  \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleaf_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m  \u001b[49m\u001b[43mconstraints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tree_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_tree_size\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# evaluate each offspring and store its fitness\u001b[39;00m\n\u001b[0;32m    225\u001b[0m difficulty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitSeeds()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seeds = []\n",
    "evo.initSeeds = initSeeds\n",
    "difficulty = 0\n",
    "evo.evolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary file created at: C:\\Users\\cosmi\\AppData\\Local\\Temp\\tmpf_vgf152\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tempfile\n",
    "best = evo.population[25]\n",
    "with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "    #temp_file.write(b'Test content')\n",
    "    print(f\"Temporary file created at: {temp_file.name}\")\n",
    "    pickle.dump(evo.population, temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'best_gp.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_gp.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Open the file in binary mode\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Serialize and write the variable to the file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(evo\u001b[38;5;241m.\u001b[39mbest_of_gens[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], file)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'best_gp.pickle'"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "\n",
    "file_path = 'best_gp.pickle'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'wb') as file:\n",
    "    # Serialize and write the variable to the file\n",
    "    pickle.dump(evo.best_of_gens[-1], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'best_evo_population.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [64]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_evo_population.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Open the file in binary mode\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Serialize and write the variable to the file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(evo, file)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'best_evo_population.pickle'"
     ]
    }
   ],
   "source": [
    "#Save population\n",
    "import pickle\n",
    "\n",
    "file_path = 'best_evo_population.pickle'\n",
    "\n",
    "# Open the file in binary mode\n",
    "with open(file_path, 'wb') as file:\n",
    "    # Serialize and write the variable to the file\n",
    "    pickle.dump(evo, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'best_gp_65.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_gp_65.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      5\u001b[0m     best \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      6\u001b[0m     evo\u001b[38;5;241m.\u001b[39mbest_of_gens\u001b[38;5;241m.\u001b[39mappend(best)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'best_gp_65.pickle'"
     ]
    }
   ],
   "source": [
    "#Load saved model\n",
    "import pickle\n",
    "file_path = 'best_gp_65.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    best = pickle.load(file)\n",
    "    evo.best_of_gens.append(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cosmi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\cosmi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\cosmi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'fitness_function_pt' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_evo_population.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m----> 6\u001b[0m     evo \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't get attribute 'fitness_function_pt' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "#Load saved population\n",
    "import pickle\n",
    "#Load saved model\n",
    "file_path = 'best_evo_population.pickle'\n",
    "with open(file_path, 'rb') as file:\n",
    "    evo = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n",
      "['sqrt(abs(x_6))', '(sin((sqrt(abs(sqrt(abs(x_3))))+max(sin(x_7),x_6)))-(sqrt(abs(x_1))*min(sqrt(abs(x_6)),(x_6/x_1))))', '(sin((sin((sqrt(abs(2.0218732357025146))*x_4))-(((x_0-x_2)+sin(max(sin((x_2-3.2183427810668945)),(max(-4.163837909698486,x_7)/(x_2+x_2)))))+x_3)))-(x_2*min(x_2,x_3)))', '(min(sin((x_3/x_1)),max((x_2-x_6),x_0))+(((x_0/x_2)+(x_2+x_7))+sqrt(abs(min(x_0,(min(sin((x_3/x_1)),max((x_2-x_6),x_0))+(((x_0/x_2)+(x_2+x_7))+sqrt(abs(min(x_0,x_4))))))))))']\n",
      "0, 24749 , -561.7845087987728\n",
      "1, 31222 , -833.0989478497987\n",
      "2, 8574 , -735.2738178258458\n",
      "3, 29418 , -487.35451553246503\n",
      "4, 6481 , -725.1912132289281\n",
      "5, 22024 , -903.4027971478529\n",
      "6, 18175 , -1021.5859771613627\n",
      "7, 14614 , -458.59184904544344\n",
      "8, 20891 , -518.9793792749485\n",
      "9, 3903 , -686.0630740740751\n",
      "10, 11354 , -553.3813547191488\n",
      "11, 6312 , -413.7812627736931\n",
      "12, 15670 , -520.2915239161096\n",
      "13, 7178 , -535.9529619801922\n",
      "14, 19701 , -452.21575387725983\n",
      "15, 920 , -547.4672146536305\n",
      "16, 19454 , -814.9611051323409\n",
      "17, 23214 , -1026.8286049728142\n",
      "18, 16536 , -747.2324205955638\n",
      "19, 28972 , -508.6245898919617\n",
      "20, 24771 , -450.50480472738434\n",
      "21, 10706 , -586.2266610278302\n",
      "22, 13767 , -503.1670067896947\n",
      "23, 25017 , -515.4642700047125\n",
      "24, 1015 , -534.5245673290755\n",
      "25, 2212 , -790.2500879415041\n",
      "26, 11423 , -650.8330237727289\n",
      "27, 30112 , -713.9437363841635\n",
      "28, 22495 , -534.3406018967745\n",
      "29, 23416 , -453.3453315086399\n",
      "30, 27691 , -624.3544781099625\n",
      "31, 3799 , -366.0379264583929\n",
      "32, 25744 , -468.1298819680982\n",
      "33, 29677 , -504.64511194733484\n",
      "34, 7160 , 12.385807952161116\n",
      "35, 3065 , -588.7794442248779\n",
      "36, 31544 , -129.8171361314036\n",
      "37, 11118 , -500.00866503892513\n",
      "38, 8351 , -102.04307101644062\n",
      "39, 23251 , -528.8356403744372\n",
      "40, 5715 , -227.05589948553234\n",
      "41, 27892 , -583.6011677687479\n",
      "42, 28735 , -207.02255207916875\n",
      "43, 2120 , -536.8664949543252\n",
      "44, 31622 , -668.8749513206764\n",
      "45, 5201 , -198.31525226023055\n",
      "46, 31108 , -555.7522571369848\n",
      "47, 20854 , -529.1845672589998\n",
      "48, 22757 , -540.3154417503251\n",
      "49, 7518 , -734.7423472558854\n",
      "50, 17770 , -452.6187881531171\n",
      "51, 22149 , -868.4217437018226\n",
      "52, 4896 , -447.17726546718274\n",
      "53, 26018 , -524.3548472425746\n",
      "54, 3028 , -528.0446124751854\n",
      "55, 15754 , -556.3664491789236\n",
      "56, 6743 , -552.2336263487609\n",
      "57, 17487 , -750.122337675672\n",
      "58, 17546 , -627.0065309713335\n",
      "59, 16344 , -402.74403797705503\n",
      "60, 30226 , -573.4915679706999\n",
      "61, 394 , -512.0264551530081\n",
      "62, 20482 , -501.26485645664286\n",
      "63, 11972 , -463.4155884699135\n",
      "64, 9603 , -101.92895195526928\n",
      "65, 23677 , -623.1821938452744\n",
      "66, 19148 , -793.114000396883\n",
      "67, 8860 , -731.279356632927\n",
      "68, 9961 , -639.1349350816222\n",
      "69, 18880 , -543.3977014256084\n",
      "70, 15007 , -452.81918850160963\n",
      "71, 9864 , -671.3413638815414\n",
      "72, 7876 , -317.2000328030899\n",
      "73, 31220 , -709.9519669330056\n",
      "74, 30754 , -90.67950864263462\n",
      "75, 5494 , -477.61578682303315\n",
      "76, 23657 , -507.48717007661674\n",
      "77, 18074 , -590.7311740074011\n",
      "78, 7117 , -67.53276171687332\n",
      "79, 23798 , -397.7551192272288\n",
      "80, 5647 , -450.9704265285158\n",
      "81, 8300 , -928.1531754170385\n",
      "82, 31621 , -565.3766933993147\n",
      "83, 24524 , -331.46799550719845\n",
      "84, 27314 , -501.3904277590881\n",
      "85, 2701 , -1055.7459410831775\n",
      "86, 13123 , -542.5002753089291\n",
      "87, 12593 , -480.13660165654363\n",
      "88, 3213 , -388.1716092920319\n",
      "89, 19070 , -611.4851755982047\n",
      "90, 15100 , -455.7144849317526\n",
      "91, 16607 , -635.4724392019903\n",
      "92, 10687 , -549.2472862147517\n",
      "93, 30141 , -744.1350906310648\n",
      "94, 2685 , -581.9311584413003\n",
      "95, 28850 , -793.5420139685857\n",
      "96, 8723 , -474.03851645193333\n",
      "97, 19268 , -800.4362086360774\n",
      "98, 7802 , -619.4345526878052\n",
      "99, 4066 , -560.3324859781007\n",
      "Score is -549.1078192030926\n",
      "Good runs 0/100\n",
      "Medium runs 0/100\n",
      "Positive runs 1/100\n",
      "Crashes 100/100\n",
      "Touches ground 0/100\n"
     ]
    }
   ],
   "source": [
    "def get_test_score(tree):\n",
    "    rewards = []\n",
    "    episodeNumber = 100\n",
    "    goodRuns = 0\n",
    "    badRuns = 0\n",
    "    touchGroundRounds = 0\n",
    "    Crashes = 0\n",
    "    mediumRuns = 0\n",
    "    positiveRuns = 0\n",
    "    for i in range(episodeNumber):\n",
    "      # get initial state\n",
    "      seed = random.randint(0,32000)\n",
    "      observation = env.reset(seed = i)\n",
    "      observation = observation[0]\n",
    "      currentReward = 0\n",
    "      touches = 0\n",
    "      crashes = 0\n",
    "\n",
    "      for j in range(500):    \n",
    "        # build up the input sample for GP\n",
    "        input_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        # get output (squeezing because it is encapsulated in an array)\n",
    "        output = tree.get_output_pt(input_sample)\n",
    "        action = torch.argmax(tree.get_output_pt(input_sample))\n",
    "        observation, reward, terminated, truncated, info = env.step(action.item())\n",
    "        rewards.append(reward)\n",
    "        currentReward += reward\n",
    "        if(reward > 99):\n",
    "          touches = touches + 1\n",
    "        if (reward < -99):\n",
    "          crashes = crashes + 1\n",
    "        output_sample = torch.from_numpy(observation.reshape((1,-1))).float()\n",
    "        if (terminated or truncated):\n",
    "            break\n",
    "      if(crashes>0):\n",
    "        Crashes = Crashes + 1\n",
    "      if(touches >= 2):\n",
    "        touchGroundRounds= touchGroundRounds+1\n",
    "      if(currentReward > 200):\n",
    "        goodRuns+=1\n",
    "      else:\n",
    "        badRuns+=1\n",
    "      if(currentReward > 150):\n",
    "        mediumRuns+=1\n",
    "      if(currentReward > 0):\n",
    "        positiveRuns+=1\n",
    "      print(f\"{i}, {seed} , {currentReward}\")\n",
    "    fitness = np.sum(rewards)\n",
    "    \n",
    "    return fitness / episodeNumber, goodRuns,goodRuns+badRuns, Crashes, touches, mediumRuns, positiveRuns\n",
    "\n",
    "\n",
    "# To test with 33,25, 48. 51, 52, 62, 64, 77, 79, 83, 94\n",
    "\n",
    "best = evo.population[25]\n",
    "difficulty = 0\n",
    "print(i)\n",
    "print(best.get_readable_repr())\n",
    "score, goodRuns,totalRuns, Crashes, touches,mediumRuns, positiveRuns = get_test_score(best)\n",
    "print(f\"Score is {score}\" )\n",
    "print(f\"Good runs {goodRuns}/{totalRuns}\")\n",
    "print(f\"Medium runs {mediumRuns}/{totalRuns}\")\n",
    "print(f\"Positive runs {positiveRuns}/{totalRuns}\")\n",
    "print(f\"Crashes {Crashes}/{totalRuns}\")\n",
    "print(f\"Touches ground {touches}/{totalRuns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make an animation\n",
    "Here the best evolved individual is selected and one episode is rendered. Make sure to save your lunar landers over time to track progress and make comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeds: [15198, 17988, 19178, 17410, 30002, 17646, 6268, 12930, 17898, 15641, 6774, 29108, 13676, 14454, 8607, 2345, 1301, 3436, 10573, 14501]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: './evolved_lander.gif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [117]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m fitness_function_pt(best, num_episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, episode_duration\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, render\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, ignore_done\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14900\u001b[39m)\n\u001b[0;32m     17\u001b[0m env\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 18\u001b[0m \u001b[43msave_frames_as_gif\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [117]\u001b[0m, in \u001b[0;36msave_frames_as_gif\u001b[1;34m(frames, path, filename)\u001b[0m\n\u001b[0;32m      9\u001b[0m     patch\u001b[38;5;241m.\u001b[39mset_data(frames[i])\n\u001b[0;32m     10\u001b[0m anim \u001b[38;5;241m=\u001b[39m animation\u001b[38;5;241m.\u001b[39mFuncAnimation(plt\u001b[38;5;241m.\u001b[39mgcf(), animate, frames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(frames), interval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43manim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagemagick\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\animation.py:1077\u001b[0m, in \u001b[0;36mAnimation.save\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1073\u001b[0m savefig_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransparent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m   \u001b[38;5;66;03m# just to be safe!\u001b[39;00m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;66;03m# canvas._is_saving = True makes the draw_event animation-starting\u001b[39;00m\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;66;03m# callback a no-op; canvas.manager = None prevents resizing the GUI\u001b[39;00m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;66;03m# widget (both are likewise done in savefig()).\u001b[39;00m\n\u001b[1;32m-> 1077\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrc_context({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavefig.bbox\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}), \\\n\u001b[0;32m   1078\u001b[0m      writer\u001b[38;5;241m.\u001b[39msaving(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fig, filename, dpi), \\\n\u001b[0;32m   1079\u001b[0m      cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fig\u001b[38;5;241m.\u001b[39mcanvas,\n\u001b[0;32m   1080\u001b[0m                        _is_saving\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m anim \u001b[38;5;129;01min\u001b[39;00m all_anim:\n\u001b[0;32m   1082\u001b[0m         anim\u001b[38;5;241m.\u001b[39m_init_draw()  \u001b[38;5;66;03m# Clear the initial frame\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\contextlib.py:142\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\animation.py:233\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\matplotlib\\animation.py:497\u001b[0m, in \u001b[0;36mPillowWriter.finish\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinish\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mappend_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_frames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\PIL\\Image.py:2428\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2426\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2427\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2428\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2430\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2431\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: './evolved_lander.gif'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "# gist to save gif from https://gist.github.com/botforge/64cbb71780e6208172bbf03cd9293553\n",
    "def save_frames_as_gif(frames, path='./', filename='evolved_lander.gif'):\n",
    "  plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi=72)\n",
    "  patch = plt.imshow(frames[0])\n",
    "  plt.axis('off')\n",
    "  def animate(i):\n",
    "      patch.set_data(frames[i])\n",
    "  anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "  anim.save(path + filename, writer='imagemagick', fps=60)\n",
    "\n",
    "frames = []\n",
    "initSeeds()\n",
    "#Please check the seed to the right\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False, seed=14900)\n",
    "env.close()\n",
    "save_frames_as_gif(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "The coefficients in the multi-tree aren't optimised. Here Q-learning (taken from https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) is used to optimise the weights further. Incorporate coefficient optimisation in training your agent(s). Coefficient Optimisation can be expensive. Think about how often you want to optimise, when, which individuals etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Bring more elaborated ideas (also taking inspiration from the scientific literature) about how the provided GP library could be improved using coefficient optimisation. Optimisation can be expensive, so consider what individuals or what portion of the population should be optimised. Important: At this stage, each idea should be formalised into a motivating hypothesis (e.g., Assuming that . . . happens, then we expect an improvement by doing . . . .\n",
    "\n",
    "---\n",
    "\n",
    "## Jack\n",
    "\n",
    "The optimization can be done periodically while evolving as well. For example: optimizing the best multitree coefficients of every generation, or every x generations.\n",
    "\n",
    "Some potentially useful papers\n",
    "1. Genetic Programming and Reinforcement Learning on Learning Heuristics for Dynamic Scheduling: A Preliminary Comparison (https://www.researchgate.net/publication/380254508_Genetic_Programming_and_Reinforcement_Learning_on_Learning_Heuristics_for_Dynamic_Scheduling_A_Preliminary_Comparison)\n",
    "2. Reinforced Genetic Programming (https://link.springer.com/article/10.1023/A:1011953410319)\n",
    "3. Multi-modal multi-objective model-based genetic programming to find multiple diverse high-quality models (https://arxiv.org/pdf/2203.13347)\n",
    "4. Multi-objective Genetic Programming Optimization of Decision Trees for Classifying Medical Data (https://link.springer.com/chapter/10.1007/978-3-540-45224-9_42)\n",
    "5. Coefficient Mutation in the Gene-pool Optimal Mixing Evolutionary Algorithm for Symbolic Regression (https://dl.acm.org/doi/pdf/10.1145/3520304.3534036)\n",
    "\n",
    "Mind here: programs in this case = multitrees\n",
    "\n",
    "Ideas:\n",
    "1. Optimizing coefficients of the best multitree of each generation during evolution. Assuming that we optimize the coefficients of the best individual in a population, increasing the fitness, its offspring will also be fitter. We expect an improvement in \"convergence rate\" (fitness improves faster). This does not affect the global structure of the trees but the coefficients get \"propagated\"\n",
    "2. The same, but not the best of every generation to save compute.\n",
    "3. Optimize the coefficients on the worst individuals. Assume that the fitness increases to the point that the program will be included in the tournament selection. Then, this program is \"saved\" from being eliminated, and will perhaps evolve into a good (or best) solution. This is kind of like exploration, avoiding a pure greedy approach.\n",
    "4. Same reasoning for optimizing the number 2 or 3, or multiple programs, but that will be very expensive so probably not good.\n",
    "5. Inspired by paper: Coefficient Mutation in the Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA). Use Gaussian coefficient mutation to mutate the coefficients to allow for more exploration, and fine-tuning solutions. This could be combined with optimizing while evolving for example. E.g. optimizing the best program and mutating it using gaussian coefficient mutation to create new programs. Then see if these programs are among the highest fitness to be selected by tournament selection. Assuming that this propagates the best solution while also exploring the solution (program) space, then this will ultimately lead to an overall better solution.\n",
    "6. Inspired by: Multi-objective Genetic Programming Optimization of Decision Trees for Classifying Medical Data. Use this technique that they are using to enhance their GP's coefficient optimization properties. But right now I don't have enough time to figure out what they did. ### TODO: LOOK AT PAPER. They state this: \"We have incorporated a Quasi-Newton optimization technique to augment the\n",
    "power ofthe GP coefficient optimization. This technique uses an error propaga-\n",
    "tion algorithm that efficiently calculates the gradient ofthe error function with\n",
    "respect to the coefficients embedded in the GP expression tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(max((min((sin(x_3)+x_4),max(((max(min(sin((x_1-x_1)),x_4),min((x_3+(x_4/x_7)),sin(x_2)))/x_3)+sqrt(abs((x_7-x_7)))),sin(nan)))/sqrt(abs(sin(sin((min(x_7,x_4)-sin(max(max(x_0,max(max(min(sin(sqrt(abs((1.2415639162063599+sqrt(abs(sin(x_5))))))),x_0),x_0),x_6)),sin(x_3))))))))),sin(x_3))-sin(sin((min(x_7,x_4)-sin(x_1)))))', '((sqrt(abs((x_1-x_7)))/min(x_7,(x_1-x_7)))*(((sin(nan)-x_0)*x_0)-min((((sin(nan)/min(x_7,(x_1-x_7)))-x_7)-max(min((x_6*max(x_7,x_7)),(max(x_5,x_4)*nan)),sin((max(((x_4+x_4)*x_2),max(x_3,x_0))/(min(sin(x_7),(x_5/x_7))*sin((max(x_5,x_4)*nan))))))),x_4)))', '((min(max(sin(sqrt(abs(x_4))),max(x_6,x_0)),sqrt(abs(x_5)))*max((sin(min(x_4,(x_0-x_7)))*(sin(x_4)*(max(sqrt(abs(sqrt(abs(sqrt(abs(max(sqrt(abs(x_5)),x_3))))))),x_7)+((min(x_4,x_1)*(x_2-(x_2-x_6)))/(max(x_5,x_4)*(x_4/min(x_3,x_2))))))),sin((sqrt(abs(x_3))/sqrt(abs(nan))))))*sqrt(abs((((nan*(x_6+x_6))*x_3)-sqrt(abs(x_6))))))', '(max((((x_6/x_7)-min(x_6,x_2))+((x_5+x_4)+x_4)),((x_4*x_3)+(x_3+(x_3/x_3))))/min(((max(x_3,x_1)-x_2)+(min(max(x_3,x_2),x_5)-(sqrt(abs(sin(x_6)))+sin((x_1-x_5))))),(x_3-sin((((sqrt(abs(x_5))*(x_2+x_4))/x_0)/x_7)))))']\n",
      "0 , -119.05972648524923\n",
      "1 , -152.42199928849408\n",
      "2 , -115.80806806546317\n",
      "3 , -135.7037643905514\n",
      "4 , -122.12365411628463\n",
      "5 , -107.5317482270973\n",
      "6 , -215.1565254088262\n",
      "7 , -133.32508979930412\n",
      "8 , -143.8927430905809\n",
      "9 , -146.92227606639244\n",
      "10 , -124.94774525289782\n",
      "11 , -120.77035613213292\n",
      "12 , -14.373581441354759\n",
      "13 , -0.979797364529901\n",
      "14 , -138.40046552198916\n",
      "15 , -105.97308828401466\n",
      "16 , -181.6049680206633\n",
      "17 , -335.37202954260164\n",
      "18 , -197.49193225320766\n",
      "19 , -136.63534250440952\n",
      "20 , -127.14607536253197\n",
      "21 , -120.22298206561811\n",
      "22 , -107.02222787125515\n",
      "23 , -126.92554800571799\n",
      "24 , -94.64883547592552\n",
      "25 , -138.4838763691316\n",
      "26 , -182.75936308140018\n",
      "27 , -174.75855297791895\n",
      "28 , -130.0857771174437\n",
      "29 , -218.56803327569378\n",
      "30 , -163.14737113600467\n",
      "31 , -109.9102165514015\n",
      "32 , -112.11347156087993\n",
      "33 , -136.0439138497199\n",
      "34 , -124.86264356308894\n",
      "35 , -154.02657822176548\n",
      "36 , -133.52652219093824\n",
      "37 , -122.9220969786611\n",
      "38 , -146.98506748184212\n",
      "39 , -137.26725757605874\n",
      "40 , -93.65456463541452\n",
      "41 , -142.7840942939363\n",
      "42 , -137.26524514914908\n",
      "43 , -147.0428098197616\n",
      "44 , -291.93441488471376\n",
      "45 , -145.17953974703315\n",
      "46 , -117.88814766064922\n",
      "47 , -101.53870640370786\n",
      "48 , -113.34364597096166\n",
      "49 , -138.56942694382462\n",
      "50 , -119.5764336900526\n",
      "51 , -180.42875174700524\n",
      "52 , -136.66531039518372\n",
      "53 , -128.22738937827035\n",
      "54 , -144.58582146781586\n",
      "55 , -167.3787529719014\n",
      "56 , -133.07071642915525\n",
      "57 , -211.03955971968705\n",
      "58 , -312.4600801298152\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "GAMMA = 0.99\n",
    "\n",
    "constants = best.get_subtrees_consts()\n",
    "\n",
    "if len(constants)>0:\n",
    "  optimizer = optim.AdamW(constants, lr=1e-3, amsgrad=True)\n",
    "\n",
    "for _ in range(500):\n",
    "\n",
    "  if len(constants)>0 and len(evo.memory)>batch_size:\n",
    "    target_tree = copy.deepcopy(best)\n",
    "\n",
    "    transitions = evo.memory.sample(batch_size)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                        batch.next_state)), dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                               if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    state_action_values = best.get_output_pt(state_batch).gather(1, action_batch)\n",
    "    next_state_values = torch.zeros(batch_size, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "      next_state_values[non_final_mask] = target_tree.get_output_pt(non_final_next_states).max(1)[0].float()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "   \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_value_(constants, 100)\n",
    "    optimizer.step()\n",
    "\n",
    "print(best.get_readable_repr())\n",
    "print(get_test_score(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = []\n",
    "fitness_function_pt(best, num_episodes=1, episode_duration=500, render=True, ignore_done=False)\n",
    "env.close()\n",
    "save_frames_as_gif(frames, filename='evolved_lander_RL.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"evolved_lander_RL.gif\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
